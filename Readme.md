# 3D Hand Pose & Shape Estimation for hand-object interaction dataset from single depth image

## Dataset

We are using recently published dataset of hand-object interaction

[HOnnotate: A method for 3D Annotation of Hand and Objects Poses](https://www.tugraz.at/institute/icg/research/team-lepetit/research-projects/hand-object-3d-pose-annotation/)

**Complexity:** Hand poses are complex and mostly occluded with objects. Objects can have many different shape and pose which makes the problem harder

**Data format:** Single monocular depthimage

### Qualitative Results--

**sample depth images**

![depth1](Results/depthorg1.png) ![depth2](Results/depthorg2.png)

**Pose Prediction Result**

![pose1](Results/git2.png) 

![pose2](Results/git1.png)

**Shape Prediction Result**

![shape1](Results/mesh3d1.png) 
![shape2](Results/mesh3d2.png)
![shape1](Results/mesh2d1.png) 
![shape2](Results/mesh2d.png)

**Sparse to Dense shape**
![dense1](Results/colored1.png) 
![dense2](Results/colored2.png)
![dense1](Results/densemesh3.png) 
![dense2](Results/densemesh4.png)

******Detail will be updated after completion of the project******

##### HOnnotate Gitlab Challenge Link [here](https://competitions.codalab.org/competitions/22485#results)


